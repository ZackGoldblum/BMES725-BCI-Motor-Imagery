{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0bd9b6b4994d3bb2f3181bdd53871f722d7a4323dd9d419f0561d20da3c614246",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "bd9b6b4994d3bb2f3181bdd53871f722d7a4323dd9d419f0561d20da3c614246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#sys.path.insert(1, r\"C:\\Users\\Zack\\OneDrive\\BCI\\arl-eegmodels-master\")\n",
    "#from EEGModels import ShallowConvNet\n",
    "\n",
    "# main directory\n",
    "main_dir = os.getcwd()\n",
    "# eeg data directory\n",
    "eeg_dir = os.path.join(main_dir, \"eeg_data\")\n",
    "# eeg validation data directory\n",
    "eeg_validation_dir = os.path.join(main_dir, \"eeg_data_validation\")\n",
    "\n",
    "MI_CLASSES = [\"left\", \"right\", \"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_sec(eeg_data, num_sec=5, samp_freq=250):\n",
    "    one_sec_data = []\n",
    "    for i in range(num_sec):\n",
    "        eeg_data_i = eeg_data[i*samp_freq:(i+1)*samp_freq]\n",
    "        one_sec_data.append(eeg_data_i)\n",
    "\n",
    "    return one_sec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data_dir):\n",
    "    training_data_dict = {}\n",
    "\n",
    "    for mi_class in MI_CLASSES:\n",
    "        if mi_class not in training_data_dict:\n",
    "            training_data_dict[mi_class] = []\n",
    "\n",
    "        mi_class_dir = os.path.join(data_dir, mi_class)\n",
    "        for filename in os.listdir(mi_class_dir):\n",
    "            if \"filtered\" in filename:\n",
    "                eeg_data = np.loadtxt(os.path.join(mi_class_dir, filename), delimiter=',')\n",
    "                one_sec_list = to_one_sec(eeg_data, num_sec=5, samp_freq=250)\n",
    "                for i in range(len(one_sec_list)):  # for each 1 second trial\n",
    "                    one_sec_data = one_sec_list[i] # (250, 8) eeg data\n",
    "                    one_sec_dataT = np.transpose(one_sec_data)  # (8, 250) eeg data\n",
    "                    training_data_dict[mi_class].append(one_sec_dataT)  \n",
    "\n",
    "    session_count = [len(training_data_dict[mi_class]) for mi_class in MI_CLASSES]\n",
    "    print(f\"One sec trial count:\\nLeft: {session_count[0]}, Right: {session_count[1]}, None: {session_count[2]}\\n\")\n",
    "\n",
    "    for mi_class in MI_CLASSES:\n",
    "        np.random.shuffle(training_data_dict[mi_class])  # randomize session order\n",
    "        training_data_dict[mi_class] = training_data_dict[mi_class][:min(session_count)]  # use min session count number of sessions\n",
    "\n",
    "    # creating X, y \n",
    "    labeled_data = []\n",
    "    for mi_class in MI_CLASSES:\n",
    "        for data in training_data_dict[mi_class]:\n",
    "            if mi_class == \"left\":\n",
    "                labeled_data.append([data, [1, 0, 0]])\n",
    "            elif mi_class == \"right\":\n",
    "                labeled_data.append([data, [0, 1, 0]])\n",
    "            elif mi_class == \"none\":\n",
    "                labeled_data.append([data, [0, 0, 1]])\n",
    "\n",
    "    np.random.shuffle(labeled_data)\n",
    "    \n",
    "    return labeled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "One sec trial count:\nLeft: 20, Right: 20, None: 20\n\n"
     ]
    }
   ],
   "source": [
    "labeled_data = create_data(data_dir=eeg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating training data...\nOne sec trial count:\nLeft: 20, Right: 20, None: 20\n\nCreating testing data...\nOne sec trial count:\nLeft: 5, Right: 5, None: 5\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training data...\")\n",
    "train_data = create_data(data_dir=eeg_dir)\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for X, y in train_data:\n",
    "    train_X.append(X)\n",
    "    train_y.append(y)\n",
    "\n",
    "print(\"Creating testing data...\")\n",
    "test_data = create_data(data_dir=eeg_validation_dir)\n",
    "test_X = []\n",
    "test_y = []\n",
    "\n",
    "for X, y in test_data:\n",
    "    test_X.append(X)\n",
    "    test_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_X shape: (60, 8, 250)\ntest_X shape: (15, 8, 250)\ntrain_y shape: (60, 3)\ntest_y shape: (15, 3)\n"
     ]
    }
   ],
   "source": [
    "#train_X = np.transpose(np.array(train_X))\n",
    "train_X = np.array(train_X)\n",
    "print(\"train_X shape: \" + str(np.shape(train_X)))\n",
    "#test_X = np.transpose(np.array(test_X))\n",
    "test_X = np.array(test_X)\n",
    "print(\"test_X shape: \" + str(np.shape(test_X)))\n",
    "\n",
    "#train_y = np.transpose(np.array(train_y))\n",
    "train_y = np.array(train_y)\n",
    "print(\"train_y shape: \" + str(np.shape(train_y)))\n",
    "#test_y = np.transpose(np.array(test_y))\n",
    "test_y = np.array(test_y)\n",
    "print(\"test_y shape: \" + str(np.shape(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def square(x):\n",
    "        return K.square(x)\n",
    "\n",
    "    def log(x):\n",
    "        return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "    def ShallowConvNet(nb_classes, Chans = 8, Samples = 250, dropoutRate = 0.5):\n",
    "        # start the model\n",
    "        input_main   = Input((Chans, Samples, 1))\n",
    "        block1       = Conv2D(40, (1, 25), \n",
    "                                        input_shape=(Chans, Samples, 1),\n",
    "                                        kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "        block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                                kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "        block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
    "        block1       = Activation(square)(block1)\n",
    "        block1       = AveragePooling2D(pool_size=(1, 75), strides=(1, 15))(block1)\n",
    "        block1       = Activation(log)(block1)\n",
    "        block1       = Dropout(dropoutRate)(block1)\n",
    "        flatten      = Flatten()(block1)\n",
    "        dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "        softmax      = Activation('softmax')(dense)\n",
    "\n",
    "        return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_8 (InputLayer)         [(None, 8, 250, 1)]       0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 8, 226, 40)        1040      \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 1, 226, 40)        12800     \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 1, 226, 40)        160       \n_________________________________________________________________\nactivation_21 (Activation)   (None, 1, 226, 40)        0         \n_________________________________________________________________\naverage_pooling2d_7 (Average (None, 1, 11, 40)         0         \n_________________________________________________________________\nactivation_22 (Activation)   (None, 1, 11, 40)         0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 1, 11, 40)         0         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 440)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 3)                 1323      \n_________________________________________________________________\nactivation_23 (Activation)   (None, 3)                 0         \n=================================================================\nTotal params: 15,323\nTrainable params: 15,243\nNon-trainable params: 80\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShallowConvNet(nb_classes=3, Chans=8, Samples=250)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer =\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "6/6 - 1s - loss: 0.9931 - accuracy: 0.7000\n",
      "Epoch 2/50\n",
      "6/6 - 0s - loss: 0.4286 - accuracy: 0.8333\n",
      "Epoch 3/50\n",
      "6/6 - 0s - loss: 1.4098 - accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "6/6 - 0s - loss: 0.4282 - accuracy: 0.8833\n",
      "Epoch 5/50\n",
      "6/6 - 0s - loss: 0.3046 - accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "6/6 - 0s - loss: 0.3463 - accuracy: 0.8333\n",
      "Epoch 7/50\n",
      "6/6 - 0s - loss: 0.2480 - accuracy: 0.9500\n",
      "Epoch 8/50\n",
      "6/6 - 0s - loss: 0.4689 - accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "6/6 - 0s - loss: 0.2019 - accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "6/6 - 0s - loss: 0.7164 - accuracy: 0.6167\n",
      "Epoch 11/50\n",
      "6/6 - 0s - loss: 0.3186 - accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "6/6 - 0s - loss: 0.4124 - accuracy: 0.8833\n",
      "Epoch 13/50\n",
      "6/6 - 0s - loss: 0.3783 - accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "6/6 - 0s - loss: 0.2314 - accuracy: 0.9500\n",
      "Epoch 15/50\n",
      "6/6 - 0s - loss: 0.1853 - accuracy: 0.9500\n",
      "Epoch 16/50\n",
      "6/6 - 0s - loss: 0.4508 - accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "6/6 - 0s - loss: 0.2381 - accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "6/6 - 0s - loss: 0.2031 - accuracy: 0.9167\n",
      "Epoch 19/50\n",
      "6/6 - 0s - loss: 0.5897 - accuracy: 0.7833\n",
      "Epoch 20/50\n",
      "6/6 - 0s - loss: 0.2499 - accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "6/6 - 0s - loss: 0.2361 - accuracy: 0.8833\n",
      "Epoch 22/50\n",
      "6/6 - 0s - loss: 0.2478 - accuracy: 0.8667\n",
      "Epoch 23/50\n",
      "6/6 - 0s - loss: 0.4414 - accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "6/6 - 0s - loss: 0.2233 - accuracy: 0.9333\n",
      "Epoch 25/50\n",
      "6/6 - 0s - loss: 0.2636 - accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "6/6 - 0s - loss: 0.2575 - accuracy: 0.9000\n",
      "Epoch 27/50\n",
      "6/6 - 0s - loss: 0.6954 - accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "6/6 - 0s - loss: 0.2232 - accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "6/6 - 0s - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "6/6 - 0s - loss: 0.1657 - accuracy: 0.9333\n",
      "Epoch 31/50\n",
      "6/6 - 0s - loss: 0.2223 - accuracy: 0.9333\n",
      "Epoch 32/50\n",
      "6/6 - 0s - loss: 0.9386 - accuracy: 0.8000\n",
      "Epoch 33/50\n",
      "6/6 - 0s - loss: 0.1970 - accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "6/6 - 0s - loss: 0.2655 - accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "6/6 - 0s - loss: 0.2922 - accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "6/6 - 0s - loss: 0.6830 - accuracy: 0.8667\n",
      "Epoch 37/50\n",
      "6/6 - 0s - loss: 0.3121 - accuracy: 0.8500\n",
      "Epoch 38/50\n",
      "6/6 - 0s - loss: 0.6046 - accuracy: 0.7667\n",
      "Epoch 39/50\n",
      "6/6 - 0s - loss: 0.1819 - accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "6/6 - 0s - loss: 0.0665 - accuracy: 0.9833\n",
      "Epoch 41/50\n",
      "6/6 - 0s - loss: 0.3383 - accuracy: 0.8167\n",
      "Epoch 42/50\n",
      "6/6 - 0s - loss: 0.4858 - accuracy: 0.7833\n",
      "Epoch 43/50\n",
      "6/6 - 0s - loss: 0.5640 - accuracy: 0.7333\n",
      "Epoch 44/50\n",
      "6/6 - 0s - loss: 0.2741 - accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "6/6 - 0s - loss: 0.3129 - accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "6/6 - 0s - loss: 0.1344 - accuracy: 0.9500\n",
      "Epoch 47/50\n",
      "6/6 - 0s - loss: 0.1847 - accuracy: 0.9333\n",
      "Epoch 48/50\n",
      "6/6 - 0s - loss: 0.1538 - accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "6/6 - 0s - loss: 0.4606 - accuracy: 0.8167\n",
      "Epoch 50/50\n",
      "6/6 - 0s - loss: 0.2917 - accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 10\n",
    "#fitted_model = model.fit(train_X, train_y, batch_size=batch_size, epochs=50, validation_data=(test_X, test_y))\n",
    "fitted_model = model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input 0 of layer max_pooling1d_2 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 60, 5, 64)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-4c813915f118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2597\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2599\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2600\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    216\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer max_pooling1d_2 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 60, 5, 64)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, (3), input_shape=np.shape(train_X)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(64, (2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(64, (2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}