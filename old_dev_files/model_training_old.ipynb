{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0bd9b6b4994d3bb2f3181bdd53871f722d7a4323dd9d419f0561d20da3c614246",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "bd9b6b4994d3bb2f3181bdd53871f722d7a4323dd9d419f0561d20da3c614246"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#sys.path.insert(1, r\"C:\\Users\\Zack\\OneDrive\\BCI\\arl-eegmodels-master\")\n",
    "#from EEGModels import ShallowConvNet\n",
    "\n",
    "# main directory\n",
    "main_dir = os.getcwd()\n",
    "# eeg data directory\n",
    "eeg_dir = os.path.join(main_dir, \"eeg_data\")\n",
    "# eeg validation data directory\n",
    "eeg_validation_dir = os.path.join(main_dir, \"eeg_data_validation\")\n",
    "\n",
    "MI_CLASSES = [\"left\", \"right\", \"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_sec(eeg_data, num_sec=5, samp_freq=250):\n",
    "    one_sec_data = []\n",
    "    for i in range(num_sec):\n",
    "        eeg_data_i = eeg_data[i*samp_freq:(i+1)*samp_freq]\n",
    "        one_sec_data.append(eeg_data_i)\n",
    "\n",
    "    return one_sec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data_dir):\n",
    "    training_data_dict = {}\n",
    "\n",
    "    for mi_class in MI_CLASSES:\n",
    "        if mi_class not in training_data_dict:\n",
    "            training_data_dict[mi_class] = []\n",
    "\n",
    "        mi_class_dir = os.path.join(data_dir, mi_class)\n",
    "        for filename in os.listdir(mi_class_dir):\n",
    "            if \"filtered\" in filename:\n",
    "                eeg_data = np.loadtxt(os.path.join(mi_class_dir, filename), delimiter=',')\n",
    "                one_sec_list = to_one_sec(eeg_data, num_sec=5, samp_freq=250)\n",
    "                for i in range(len(one_sec_list)):  # for each 1 second trial\n",
    "                    one_sec_data = one_sec_list[i] # (250, 8) eeg data\n",
    "                    one_sec_dataT = np.transpose(one_sec_data)  # (8, 250) eeg data\n",
    "                    training_data_dict[mi_class].append(one_sec_dataT)  \n",
    "\n",
    "    print(\"Trials per class: \" + str(int(len(os.listdir(mi_class_dir))/3)) + \"\\n\")\n",
    "    session_count = [len(training_data_dict[mi_class]) for mi_class in MI_CLASSES]\n",
    "    print(f\"One sec trial count:\\nLeft: {session_count[0]}, Right: {session_count[1]}, None: {session_count[2]}\\n\")\n",
    "\n",
    "    for mi_class in MI_CLASSES:\n",
    "        np.random.shuffle(training_data_dict[mi_class])  # randomize session order\n",
    "        training_data_dict[mi_class] = training_data_dict[mi_class][:min(session_count)]  # use min session count number of sessions\n",
    "\n",
    "    # creating X, y \n",
    "    labeled_data = []\n",
    "    for mi_class in MI_CLASSES:\n",
    "        for data in training_data_dict[mi_class]:\n",
    "            if mi_class == \"left\":\n",
    "                labeled_data.append([data, [1, 0, 0]])\n",
    "            elif mi_class == \"right\":\n",
    "                labeled_data.append([data, [0, 1, 0]])\n",
    "            elif mi_class == \"none\":\n",
    "                labeled_data.append([data, [0, 0, 1]])\n",
    "\n",
    "    np.random.shuffle(labeled_data)\n",
    "    \n",
    "    return labeled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trials per class: 15\n\nOne sec trial count:\nLeft: 75, Right: 75, None: 75\n\n"
     ]
    }
   ],
   "source": [
    "labeled_data = create_data(data_dir=eeg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trials per class: 15\n\nOne sec trial count:\nLeft: 75, Right: 75, None: 75\n\nCreating labeled data...\nlabeled_data_X: (225, 8, 250)\nlabeled_data_y: (225, 3)\n\nCreating testing data...\nlabeled_data_X: (9, 8, 250)\nlabeled_data_y: (9, 3)\n\nCreating training data...\nlabeled_data_X: (3, 8, 250)\nlabeled_data_y: (3, 3)\n\nCreating validation data...\nlabeled_data_X: (213, 8, 250)\nlabeled_data_y: (213, 3)\n\n"
     ]
    }
   ],
   "source": [
    "labeled_data = create_data(data_dir=eeg_dir)\n",
    "\n",
    "print(\"Creating labeled data...\")\n",
    "labeled_data_X = []\n",
    "labeled_data_y = []\n",
    "\n",
    "for X, y in labeled_data:\n",
    "    labeled_data_X.append(X)\n",
    "    labeled_data_y.append(y)\n",
    "print(\"labeled_data_X: \" + str(np.shape(labeled_data_X)))\n",
    "print(\"labeled_data_y: \" + str(np.shape(labeled_data_y)) + \"\\n\")\n",
    "\n",
    "print(\"Creating testing data...\")\n",
    "train_X = labeled_data_X[0:9]\n",
    "train_y = labeled_data_y[0:9]\n",
    "print(\"labeled_data_X: \" + str(np.shape(train_X)))\n",
    "print(\"labeled_data_y: \" + str(np.shape(train_y)) + \"\\n\")\n",
    "\n",
    "print(\"Creating training data...\")\n",
    "test_X = labeled_data_X[9:12]\n",
    "test_y = labeled_data_y[9:12]\n",
    "print(\"labeled_data_X: \" + str(np.shape(test_X)))\n",
    "print(\"labeled_data_y: \" + str(np.shape(test_y)) + \"\\n\")\n",
    "\n",
    "print(\"Creating validation data...\")\n",
    "validation_X = labeled_data_X[12:]\n",
    "validation_y = labeled_data_y[12:]\n",
    "print(\"labeled_data_X: \" + str(np.shape(validation_X)))\n",
    "print(\"labeled_data_y: \" + str(np.shape(validation_y)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8, 250)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "np.shape(labeled_data_X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_X shape: (60, 8, 250)\ntest_X shape: (15, 8, 250)\ntrain_y shape: (60, 3)\ntest_y shape: (15, 3)\n"
     ]
    }
   ],
   "source": [
    "#train_X = np.transpose(np.array(train_X))\n",
    "train_X = np.array(train_X)\n",
    "print(\"train_X shape: \" + str(np.shape(train_X)))\n",
    "#test_X = np.transpose(np.array(test_X))\n",
    "test_X = np.array(test_X)\n",
    "print(\"test_X shape: \" + str(np.shape(test_X)))\n",
    "\n",
    "#train_y = np.transpose(np.array(train_y))\n",
    "train_y = np.array(train_y)\n",
    "print(\"train_y shape: \" + str(np.shape(train_y)))\n",
    "#test_y = np.transpose(np.array(test_y))\n",
    "test_y = np.array(test_y)\n",
    "print(\"test_y shape: \" + str(np.shape(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def square(x):\n",
    "        return K.square(x)\n",
    "\n",
    "    def log(x):\n",
    "        return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "    def ShallowConvNet(nb_classes, Chans = 8, Samples = 250, dropoutRate = 0.5):\n",
    "        # start the model\n",
    "        input_main   = Input((Chans, Samples, 1))\n",
    "        block1       = Conv2D(40, (1, 25), \n",
    "                                        input_shape=(Chans, Samples, 1),\n",
    "                                        kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "        block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                                kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "        block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
    "        block1       = Activation(square)(block1)\n",
    "        block1       = AveragePooling2D(pool_size=(1, 75), strides=(1, 15))(block1)\n",
    "        block1       = Activation(log)(block1)\n",
    "        block1       = Dropout(dropoutRate)(block1)\n",
    "        flatten      = Flatten()(block1)\n",
    "        dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "        softmax      = Activation('softmax')(dense)\n",
    "\n",
    "        return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 8, 250, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 8, 226, 40)        1040      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 1, 226, 40)        12800     \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1, 226, 40)        160       \n_________________________________________________________________\nactivation (Activation)      (None, 1, 226, 40)        0         \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 1, 11, 40)         0         \n_________________________________________________________________\nactivation_1 (Activation)    (None, 1, 11, 40)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1, 11, 40)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 440)               0         \n_________________________________________________________________\ndense (Dense)                (None, 3)                 1323      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 3)                 0         \n=================================================================\nTotal params: 15,323\nTrainable params: 15,243\nNon-trainable params: 80\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShallowConvNet(nb_classes=3, Chans=8, Samples=250)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer =\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 49ms/step - loss: 1.4404 - accuracy: 0.5388 - val_loss: 1.4870 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9836 - accuracy: 0.5824 - val_loss: 1.0343 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.6979 - val_loss: 0.8666 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3960 - accuracy: 0.8433 - val_loss: 1.8795 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4176 - accuracy: 0.8574 - val_loss: 2.8428 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5414 - accuracy: 0.8207 - val_loss: 2.4045 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6002 - accuracy: 0.7979 - val_loss: 2.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0130 - accuracy: 0.6198 - val_loss: 2.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.9043 - val_loss: 1.6069 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3273 - accuracy: 0.9400 - val_loss: 1.5000 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2562 - accuracy: 0.9164 - val_loss: 5.5147 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3300 - accuracy: 0.9236 - val_loss: 2.2415 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1633 - accuracy: 0.9429 - val_loss: 0.6469 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2731 - accuracy: 0.9029 - val_loss: 1.4051 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.5663 - accuracy: 0.5467 - val_loss: 3.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4123 - accuracy: 0.8179 - val_loss: 2.9968 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4235 - accuracy: 0.8440 - val_loss: 1.6626 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4796 - accuracy: 0.8702 - val_loss: 3.0094 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.6112 - val_loss: 1.3236 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3022 - accuracy: 0.9443 - val_loss: 0.5792 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1824 - accuracy: 0.9793 - val_loss: 2.9140 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8886 - accuracy: 0.6333 - val_loss: 3.7589 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3387 - accuracy: 0.8879 - val_loss: 2.1994 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6103 - accuracy: 0.6095 - val_loss: 4.7000 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2543 - accuracy: 0.9067 - val_loss: 0.2829 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6893 - accuracy: 0.7429 - val_loss: 1.9070 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9954 - accuracy: 0.6810 - val_loss: 5.1878 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.8888 - val_loss: 0.3214 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4349 - accuracy: 0.8417 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6030 - accuracy: 0.6971 - val_loss: 3.2692 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5073 - accuracy: 0.7879 - val_loss: 1.1851 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1196 - accuracy: 0.9698 - val_loss: 1.7171 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1689 - accuracy: 0.9164 - val_loss: 1.5937 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2352 - accuracy: 0.9395 - val_loss: 1.2190 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1891 - accuracy: 0.9633 - val_loss: 0.2697 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5293 - accuracy: 0.7405 - val_loss: 0.4416 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1727 - accuracy: 0.9462 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1634 - accuracy: 0.9776 - val_loss: 0.2350 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3133 - accuracy: 0.9014 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9562 - val_loss: 0.9430 - val_accuracy: 0.4000\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2255 - accuracy: 0.9155 - val_loss: 0.3691 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2050 - accuracy: 0.9640 - val_loss: 1.1134 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0987 - accuracy: 0.9840 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1066 - accuracy: 0.9952 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2640 - accuracy: 0.8671 - val_loss: 0.2771 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0914 - accuracy: 0.9905 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1043 - accuracy: 0.9626 - val_loss: 0.7064 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.9848 - val_loss: 0.4220 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0730 - accuracy: 0.9876 - val_loss: 0.3912 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 10\n",
    "fitted_model = model.fit(train_X, train_y, batch_size=batch_size, epochs=50, validation_data=(test_X, test_y))\n",
    "#fitted_model = model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input 0 of layer max_pooling1d_2 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 60, 5, 64)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-4c813915f118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2597\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2599\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2600\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    216\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer max_pooling1d_2 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 60, 5, 64)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, (3), input_shape=np.shape(train_X)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(64, (2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(64, (2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}